{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/OoI8D/cJPeVY05LVZ90C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armin-Abdollahi/Machine-Learning/blob/main/Principal_Component_Analysis_(PCA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Principal Component Analysis (PCA)\n",
        "\n",
        "Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform a high-dimensional dataset into a lower-dimensional one by identifying the directions (principal components) that capture the maximum variance in the data. PCA is widely used for data visualization, noise reduction, and speeding up machine learning algorithms by reducing the number of features.\n",
        "\n",
        "Hereâ€™s a simple implementation using Scikit-Learn:"
      ],
      "metadata": {
        "id": "LAHjQBrJOgEP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzX-Y_8rOW30",
        "outputId": "9522802c-6a68-4ff9-b351-9317d1e74d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Data:\n",
            " [[-4.04284848e+00 -1.24000564e-01]\n",
            " [-2.31516714e+00 -1.04859727e-03]\n",
            " [-5.87485803e-01  1.21903370e-01]\n",
            " [ 2.86787688e+00  3.67807304e-01]\n",
            " [ 4.07762455e+00 -3.64661512e-01]]\n",
            "Ecplained Variance Ration: [0.99367589 0.00632411]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (e.g., points in 3D space)\n",
        "X = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5], [5, 6, 7], [5, 7, 8]])\n",
        "\n",
        "# Initialize and fit the model\n",
        "pca = PCA(n_components=2) #Reducing to 2 dimensions\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "print(\"Reduced Data:\\n\", X_reduced)\n",
        "print(\"Ecplained Variance Ration:\", pca.explained_variance_ratio_)"
      ]
    }
  ]
}
