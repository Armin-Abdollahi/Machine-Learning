{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh+Ze5Z9PEt0LK8/Gm+gJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armin-Abdollahi/Machine-Learning/blob/main/Self_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-Training\n",
        "\n",
        "Self-Training is a semi-supervised learning approach that leverages a small labeled dataset alongside a larger unlabeled dataset. The model is initially trained on labeled data, and then it makes predictions on the unlabeled data. The confident predictions (those with high certainty) are then added to the labeled dataset, and the process is repeated to improve the model.\n",
        "\n",
        "Hereâ€™s a simple example using Scikit-Learn:"
      ],
      "metadata": {
        "id": "AA-jwnNZhl1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPvBBU_ohVjH",
        "outputId": "23f93308-cfce-439b-8ce2-9c48a15ae872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8833333333333333\n"
          ]
        }
      ],
      "source": [
        "# Import nessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=200, n_features=5, random_state=42)\n",
        "X_labeled, X_unlabeled, y_labeled, _ = train_test_split(X, y, test_size=0.7, random_state=42)\n",
        "\n",
        "# Initialize and train the model with labeled data\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_labeled, y_labeled)\n",
        "\n",
        "# Perform self-training on unlabeled data\n",
        "for _ in range(5): # Repeat the process 5 times for iterative training\n",
        "    if X_unlabeled.shape[0] == 0:  # Stop if there are no more unlabeled samples\n",
        "        break\n",
        "    # Predict probabilities on the unlabeled data\n",
        "    probs = model.predict_proba(X_unlabeled)\n",
        "    high_confidence_idx = np.where(np.max(probs, axis=1) > 0.9)[0] # Select confident predictions\n",
        "\n",
        "    if len(high_confidence_idx) == 0:  # Stop if no high-confidence samples are found\n",
        "        break\n",
        "\n",
        "    # Add high-confidence predictions to labeled data\n",
        "    X_labeled = np.vstack([X_labeled, X_unlabeled[high_confidence_idx]])\n",
        "    y_labeled = np.hstack([y_labeled, model.predict(X_unlabeled[high_confidence_idx])])\n",
        "\n",
        "    # Remove confident samples from the unlabeled dataset\n",
        "    X_unlabeled = np.delete(X_unlabeled, high_confidence_idx, axis=0)\n",
        "\n",
        "    # Re-train the model on the expanded labeled dataset\n",
        "    model.fit(X_labeled, y_labeled)\n",
        "\n",
        "# Final evaluation on a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ]
}